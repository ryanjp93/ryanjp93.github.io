<div class="open-Wrapper">
	<header class="open-Title">Football Stat Crawler</header>
	<p class="open-Subtitle">JavaScript, Python, Nightmare.js, Web Crawler</p>
	<p class="open-Description">
		<span class="bold">Programming Language:</span> JavaScript (data gathering), Python (run script, spreadsheet manipulation)<br>
		<span class="bold">Tools:</span> Nightmare.js<br>
		<span class="bold">Year:</span> 2016<br>
		<span class="bold">Team Size:</span> Solo<br>
		<span class="bold">Reason:</span> Request (unprofessional- from a friend)<br>
	</p>
	<p class="open-Description">
		<span class="bold">Overview<br></span>
		Detailed statistics from recent football games are not easy to find without buying an expensive <a class="downloadLink" href="http://www.optasports.com/" target="_blank">Opta</a> subscription.
		The request for this project was to find a way to interpret an SVG element hosted on a specific <a class="downloadLink" href="http://www.squawka.com/match-results" target="_blank">website</a> 
		to determine how many shots each team had in different zones of the pitch and if possible to automatically write this information to the given spreadsheet. The project went a step further and is
	       	capable of repeating this for every game played during that week. There are three key parts to this project: the browser automation part which uses JavaScript and Nightmare.js, this visits the site
	        to gather the data and outputs it as a JSON file, The spreadsheet part, which uses Python to take the JSON file and write it to a spreadsheet, and finally the run script, also using Python,
	       	responsible for tying the program together and reporting any errors that occur.
	</p>
	<div class="gallery">
		<div class="open-Image">
			<span class="hidden">stats.png</span>
			<div class="open-Spinner">
				<div class="tile-Bounce1"></div>
				<div class="tile-Bounce2"></div>
			</div>	
		</div>
		<div class="open-Image">
			<span class="hidden">stats-0.png</span>
			<div class="open-Spinner">
				<div class="tile-Bounce1"></div>
				<div class="tile-Bounce2"></div>
			</div>	
		</div>
		<div class="open-Image">
			<span class="hidden">stats-1.png</span>
			<div class="open-Spinner">
				<div class="tile-Bounce1"></div>
				<div class="tile-Bounce2"></div>
			</div>	
		</div>
	</div>
	<p class="open-Description">
		<span class="bold">Comments<br></span>
		Prior to starting this project I had expected to face most of the challenge in trying to interpret the SVG data. However, since the website had used simple CSS selectors it was straightforward to 
		gather the information. Instead, the difficulty came from finding a browser automation library. I had initially planned to use Phantom.js but after encountering a number of problems I found that 
		the Nightmare.js library, which sits on top of Phantom.js, was much easier to use. Another unexpected issue came from the requests to the website occasionally stalling, likely due to the website
		not loading in time after automated mouse clicks, which was solved by resending the request after a set interval if there was no response. The spreadsheet manipulation was also unexpectedly
		straightforward due to pythons's xlrd package.
	</p>
</div>
